# Ultralytics
Ultralytics' YOLOv8 is a state of the art model that supports a variety of vision tasks like detection, segmentation, pose estimation, tracking, and classification. Check out Ultralytics' [repo](https://github.com/ultralytics/ultralytics)  & [documentation](https://docs.ultralytics.com/)

YOLOv8 makes the task of training your models really easy and seamless, and the library also comes with a pretained version of all it's models. For this project, we used the smallest model i.e. the Yolov8n (nano) for training. Again, we took Trashnet's [dataset](https://www.kaggle.com/datasets/feyzazkefe/trashnet) by Feyza Ozkefe. We annotated the dataset with the help of [cvat.ai](https://www.cvat.ai/), an amazing tool to annotate your dataset. To test the trained model we used Google's in-built code snippet that allows you to access your local camera to capture images and then store them temporarily as jpg file. The file is then given as an input to the model and the output classifies the object as glass, metal, cardboard, paper and plastic and makes a boundary box around the object. However, when I first trained the model, I only took a small portion of the dataset for training as annotating a dataset of more than 2500 images is a time consuming task for a single person. This caused the accuracy to drop, which was later fixed by increasing the amount of `epochs`, an `epoch` can be understood as a cycle of giving data for training of the model. After every cycle, the model's weights are adjusted, which in turn improves it's accuracy. However, there's a limit to what can be achieved by just increasing the cycles of data, thus we plan on improving the amount of data we give to the model and adding more layers before training. 
